{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W :  <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[1.]], dtype=float32)>\n",
      "b :  <tf.Variable 'Variable:0' shape=(1, 1) dtype=float32, numpy=array([[0.]], dtype=float32)>\n",
      "y_data: ,  [1.0] prediction :  tf.Tensor([[1.]], shape=(1, 1), dtype=float32)\n",
      "y_data: ,  [3.0] prediction :  tf.Tensor([[2.]], shape=(1, 1), dtype=float32)\n",
      "y_data: ,  [5.0] prediction :  tf.Tensor([[3.]], shape=(1, 1), dtype=float32)\n",
      "y_data: ,  [7.0] prediction :  tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "## data 선언\n",
    "x_data =[[1.],[2.],[3.],[4.]]\n",
    "y_data =[[1.],[3.],[5.],[7.]]\n",
    "\n",
    "## 평균 0, 분산 1의 파라미터의 정규분포로 부터 값을 가져옴.\n",
    "# 학습을 통해 업데이트가 되어 변화되는 모델의 파라미터인 w,b를 의미한다.\n",
    "W= tf.Variable(tf.random.normal((1,1), mean=1, stddev=0))\n",
    "b= tf.Variable(tf.random.normal((1,1), mean=0, stddev=0))\n",
    "print(\"W : \", W)\n",
    "print(\"b : \", b)\n",
    "\n",
    "for j in range(len(x_data)):\n",
    "    ## data * weight\n",
    "    WX =tf.matmul([x_data[j]], W)\n",
    "\n",
    "    ## bias add\n",
    "    y_hat = tf.add(WX, b)\n",
    "\n",
    "    ## W와 b로 예측 하기\n",
    "    print(\"y_data: , \",y_data[j], \"prediction : \", y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
